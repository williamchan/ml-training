{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tAggregate the data into one labeled data set.\n",
    "2.\tStore the labels in a separate file with the following on a separate line for each email file: \n",
    "EMAIL_ID\tLABEL (with a tab in between)\n",
    "3.\tDivide the data into 10 “folds” (or subsets)\n",
    "4.\tIteratively hold out one of the folds as test data.  Train on the other 9.\n",
    "5.\tRecord the results in a master results file.  The form should be\n",
    "EMAIL_ID\tLABEL        CLASSIFIED_AS (with tabs in between)\n",
    "6.\tBy the end of all 10 experiments, all of the email files will have been part of a test set, and your master results file will contain results for the whole data set\n",
    "7.\tCompute Precision, Recall, F-score and Accuracy for the complete experiment.\n",
    "8.\tRepeat the 10-fold experiment again, but don’t do smoothing.  Instead, just ignore any unseen words.  That is, just don’t add them to your running total of log-probs.  Compute all stats.  Does smoothing matter for this problem or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from util import extract_word, get_words, process_files, predict, summary, get_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ham_dir = 'ham'\n",
    "ham_filelist = ham_dir + '/hamFileList.txt'\n",
    "spam_dir = 'spam'\n",
    "spam_filelist = spam_dir + '/spamFileList.txt'\n",
    "test_dir = 'test'\n",
    "truth_file = test_dir + '/truth'\n",
    "\n",
    "ham_files = []\n",
    "spam_files = []\n",
    "test_files = [(test_dir + '/' + str(x)) for x in range(1, 101)]\n",
    "\n",
    "with open(ham_filelist, 'r') as f:\n",
    "  for line in f:\n",
    "    ham_files.append(ham_dir + '/' + str(int(line)))\n",
    "\n",
    "with open(spam_filelist, 'r') as f:\n",
    "  for line in f:\n",
    "    spam_files.append(spam_dir + '/' + str(int(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "truths = get_truths(truth_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Aggregate the data into one labeled data set.\n",
    "all_labels = {}\n",
    "all_files = []\n",
    "for ham in ham_files:\n",
    "  all_files.append(ham)\n",
    "  all_labels[ham] = 'Ham'\n",
    "for spam in spam_files:\n",
    "  all_files.append(spam)\n",
    "  all_labels[spam] = 'Spam'\n",
    "for f,l in truths.iteritems():\n",
    "  all_files.append(f)\n",
    "  all_labels[f] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "print len(all_labels)\n",
    "print len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Store the labels in a separate file with the following on a separate line for each email file: \n",
    "# EMAIL_ID LABEL (with a tab in between)\n",
    "with open('all_labels.txt', 'w') as f:\n",
    "  for k,l in all_labels.iteritems():\n",
    "    f.write(k + '\\t' + l + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Divide the data into 10 “folds” (or subsets)\n",
    "num_folds = 10\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "shuffle(all_files)\n",
    "folds = np.array_split(all_files, num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(fold_train, all_labels):\n",
    "  ham_map = {}\n",
    "  spam_map = {}\n",
    "  total_ham_words = 0\n",
    "  total_spam_words = 0\n",
    "  \n",
    "  for file in fold_train:\n",
    "    if all_labels[file] == 'Ham':\n",
    "      for w in get_words(file):\n",
    "        if w in ham_map:\n",
    "          ham_map[w] = ham_map[w] + 1\n",
    "        else:\n",
    "          ham_map[w] = 1\n",
    "        total_ham_words += 1\n",
    "    else:\n",
    "      for w in get_words(file):\n",
    "        if w in spam_map:\n",
    "          spam_map[w] = spam_map[w] + 1\n",
    "        else:\n",
    "          spam_map[w] = 1\n",
    "        total_spam_words += 1      \n",
    "  return ham_map, total_ham_words, spam_map, total_spam_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4. Iteratively hold out one of the folds as test data. Train on the other 9.\n",
    "\n",
    "all_predictions = {}\n",
    "\n",
    "all_files_array = np.array(all_files)\n",
    "fold_size = len(all_files)/num_folds\n",
    "\n",
    "for fold in range(num_folds):\n",
    "  fold_test = folds[fold]\n",
    "  train_mask = range(0,fold_size*fold) + range(fold_size*(fold+1),fold_size*num_folds)\n",
    "  fold_train = all_files_array[train_mask]\n",
    "\n",
    "  ham_map, total_ham_words, spam_map, total_spam_words = process(fold_train, all_labels)\n",
    "  predictions = predict(fold_test, ham_map, total_ham_words, spam_map, total_spam_words, 1, 200000)\n",
    "  all_predictions.update(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5. Record the results in a master results file. The form should be EMAIL_ID LABEL CLASSIFIED_AS \n",
    "# (with tabs in between)\n",
    "# 6. By the end of all 10 experiments, all of the email files will have been part of a test set, and your master\n",
    "# results file will contain results for the whole data set\n",
    "\n",
    "with open('all_predictions.txt', 'w') as f:\n",
    "  for k,p in all_predictions.iteritems():\n",
    "    label = all_labels[k]\n",
    "    f.write(k + '\\t' + label + '\\t' + p + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive = 499\n",
      "False positive = 5\n",
      "False negative = 51\n",
      "True negative = 545\n",
      "Precision = 0.990079365079\n",
      "Recall = 0.907272727273\n",
      "F-score = 0.946869070209\n",
      "Accuracy = 0.949090909091\n"
     ]
    }
   ],
   "source": [
    "# 7. Compute Precision, Recall, F-score and Accuracy for the complete experiment.\n",
    "tp, tn, fp, fn, precision, recall, fscore, accuracy = summary(all_predictions, all_labels)\n",
    "\n",
    "print \"True positive = \" + str(tp)\n",
    "print \"False positive = \" + str(fp)\n",
    "print \"False negative = \" + str(fn)\n",
    "print \"True negative = \" + str(tn)\n",
    "print \"Precision = \" + str(precision)\n",
    "print \"Recall = \" + str(recall)\n",
    "print \"F-score = \" + str(fscore)\n",
    "print \"Accuracy = \" + str(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive = 41\n",
      "False positive = 543\n",
      "False negative = 509\n",
      "True negative = 7\n",
      "Precision = 0.0702054794521\n",
      "Recall = 0.0745454545455\n",
      "F-score = 0.0723104056437\n",
      "Accuracy = 0.0436363636364\n"
     ]
    }
   ],
   "source": [
    "# 8. Repeat the 10-fold experiment again, but don’t do smoothing. Instead, just ignore any unseen words. \n",
    "# That is, just don’t add them to your running total of log-probs. Compute all stats. Does smoothing matter \n",
    "# for this problem or not?\n",
    "\n",
    "all_predictions_no_smoothing = {}\n",
    "\n",
    "for fold in range(num_folds):\n",
    "  fold_test = folds[fold]\n",
    "  train_mask = range(0,fold_size*fold) + range(fold_size*(fold+1),fold_size*num_folds)\n",
    "  fold_train = all_files_array[train_mask]\n",
    "\n",
    "  ham_map, total_ham_words, spam_map, total_spam_words = process(fold_train, all_labels)\n",
    "  predictions = predict(fold_test, ham_map, total_ham_words, spam_map, total_spam_words, 1, 200000, smooth=False)\n",
    "  all_predictions_no_smoothing.update(predictions)\n",
    "\n",
    "tp, tn, fp, fn, precision, recall, fscore, accuracy = summary(all_predictions_no_smoothing, all_labels)\n",
    "print \"True positive = \" + str(tp)\n",
    "print \"False positive = \" + str(fp)\n",
    "print \"False negative = \" + str(fn)\n",
    "print \"True negative = \" + str(tn)\n",
    "print \"Precision = \" + str(precision)\n",
    "print \"Recall = \" + str(recall)\n",
    "print \"F-score = \" + str(fscore)\n",
    "print \"Accuracy = \" + str(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
